{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q&A using LLAMA2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=DirectoryLoader(r'C:\\Users\\Sayantika\\OneDrive - IIT Delhi\\Desktop\\GenerativeAI\\data',\n",
    "                       glob=\"*.pdf\",\n",
    "                       loader_cls=PyPDFLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "print(type(documents))\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "342\n"
     ]
    }
   ],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "                                             chunk_size=500,\n",
    "                                             chunk_overlap=50)\n",
    "text_chunks=text_splitter.split_documents(documents)\n",
    "print(type(text_chunks))\n",
    "print(len(text_chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sayantika\\anaconda3\\envs\\cpullama\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Sayantika\\anaconda3\\envs\\cpullama\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Sayantika\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', \n",
    "                                 model_kwargs={'device':'cpu'})\n",
    "\n",
    "\n",
    "\n",
    "vector_store=FAISS.from_documents(text_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=r\"C:\\Users\\Sayantika\\OneDrive - IIT Delhi\\Desktop\\GenerativeAI\\model\\llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':128,\n",
    "                          'temperature':0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"Use the following pieces of information to answer the user's question.\n",
    "If you dont know the answer just say you know, don't try to make up an answer.\n",
    "\n",
    "Context:{context}\n",
    "Question:{question}\n",
    "\n",
    "Only return the helpful answer below and nothing else\n",
    "Helpful answer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt=PromptTemplate(template=template, input_variables=['context', 'question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sayantika\\anaconda3\\envs\\cpullama\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:ISO (International Organization for Standardization) is an independent, non-governmental international organization with a membership of 163 national standards bodies. ISO develops and publishes technical standards for various industries, including construction, engineering, and project management. The new ISO 19650 standards are related to information management in the context of building information modelling (BIM) and project management.\n"
     ]
    }
   ],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                   chain_type='stuff',\n",
    "                                   retriever=vector_store.as_retriever(search_kwargs={'k': 2}),\n",
    "                                   return_source_documents=False,\n",
    "                                   chain_type_kwargs={'prompt': qa_prompt})\n",
    "\n",
    "\n",
    "\n",
    "user_input = \"what are iso standards\"\n",
    "\n",
    "\n",
    "result=chain({'query':user_input})\n",
    "print(f\"Answer:{result['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:OIR stands for Organizational Information Requirements. It is a template used in ISO 19650 to capture the high-level information requirements of an organization. The OIR template includes sections such as:\n",
      "\n",
      "* Project Description\n",
      "* Stakeholders\n",
      "* Functional and Performance Requirements\n",
      "* Data Management Plans\n",
      "* Information Delivery Plans\n",
      "\n",
      "The OIR template is used to identify the key pieces of information that an organization needs to deliver in order to meet its business objectives. It helps organizations to focus on the most important information requirements and ensure that they are captured and managed\n"
     ]
    }
   ],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                   chain_type='stuff',\n",
    "                                   retriever=vector_store.as_retriever(search_kwargs={'k': 2}),\n",
    "                                   return_source_documents=False,\n",
    "                                   chain_type_kwargs={'prompt': qa_prompt})\n",
    "\n",
    "\n",
    "\n",
    "user_input = \"Can you explain about OIR template\"\n",
    "\n",
    "\n",
    "result=chain({'query':user_input})\n",
    "print(f\"Answer:{result['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of tokens (513) exceeded maximum context length (512).\n",
      "Number of tokens (514) exceeded maximum context length (512).\n",
      "Number of tokens (515) exceeded maximum context length (512).\n",
      "Number of tokens (516) exceeded maximum context length (512).\n",
      "Number of tokens (517) exceeded maximum context length (512).\n",
      "Number of tokens (518) exceeded maximum context length (512).\n",
      "Number of tokens (519) exceeded maximum context length (512).\n",
      "Number of tokens (520) exceeded maximum context length (512).\n",
      "Number of tokens (521) exceeded maximum context length (512).\n",
      "Number of tokens (522) exceeded maximum context length (512).\n",
      "Number of tokens (523) exceeded maximum context length (512).\n",
      "Number of tokens (524) exceeded maximum context length (512).\n",
      "Number of tokens (525) exceeded maximum context length (512).\n",
      "Number of tokens (526) exceeded maximum context length (512).\n",
      "Number of tokens (527) exceeded maximum context length (512).\n",
      "Number of tokens (528) exceeded maximum context length (512).\n",
      "Number of tokens (529) exceeded maximum context length (512).\n",
      "Number of tokens (530) exceeded maximum context length (512).\n",
      "Number of tokens (531) exceeded maximum context length (512).\n",
      "Number of tokens (532) exceeded maximum context length (512).\n",
      "Number of tokens (533) exceeded maximum context length (512).\n",
      "Number of tokens (534) exceeded maximum context length (512).\n",
      "Number of tokens (535) exceeded maximum context length (512).\n",
      "Number of tokens (536) exceeded maximum context length (512).\n",
      "Number of tokens (537) exceeded maximum context length (512).\n",
      "Number of tokens (538) exceeded maximum context length (512).\n",
      "Number of tokens (539) exceeded maximum context length (512).\n",
      "Number of tokens (540) exceeded maximum context length (512).\n",
      "Number of tokens (541) exceeded maximum context length (512).\n",
      "Number of tokens (542) exceeded maximum context length (512).\n",
      "Number of tokens (543) exceeded maximum context length (512).\n",
      "Number of tokens (544) exceeded maximum context length (512).\n",
      "Number of tokens (545) exceeded maximum context length (512).\n",
      "Number of tokens (546) exceeded maximum context length (512).\n",
      "Number of tokens (547) exceeded maximum context length (512).\n",
      "Number of tokens (548) exceeded maximum context length (512).\n",
      "Number of tokens (549) exceeded maximum context length (512).\n",
      "Number of tokens (550) exceeded maximum context length (512).\n",
      "Number of tokens (551) exceeded maximum context length (512).\n",
      "Number of tokens (552) exceeded maximum context length (512).\n",
      "Number of tokens (553) exceeded maximum context length (512).\n",
      "Number of tokens (554) exceeded maximum context length (512).\n",
      "Number of tokens (555) exceeded maximum context length (512).\n",
      "Number of tokens (556) exceeded maximum context length (512).\n",
      "Number of tokens (557) exceeded maximum context length (512).\n",
      "Number of tokens (558) exceeded maximum context length (512).\n",
      "Number of tokens (559) exceeded maximum context length (512).\n",
      "Number of tokens (560) exceeded maximum context length (512).\n",
      "Number of tokens (561) exceeded maximum context length (512).\n",
      "Number of tokens (562) exceeded maximum context length (512).\n",
      "Number of tokens (563) exceeded maximum context length (512).\n",
      "Number of tokens (564) exceeded maximum context length (512).\n",
      "Number of tokens (565) exceeded maximum context length (512).\n",
      "Number of tokens (566) exceeded maximum context length (512).\n",
      "Number of tokens (567) exceeded maximum context length (512).\n",
      "Number of tokens (568) exceeded maximum context length (512).\n",
      "Number of tokens (569) exceeded maximum context length (512).\n",
      "Number of tokens (570) exceeded maximum context length (512).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:The members of the EFCA BIM Task Force are:\n",
      "• Christophe Castaing (CINOV-SYNTEC, France)\n",
      "• Daan Alsem (Koninklijke NLIngenieurs, the Netherlands)\n",
      "• Ingrid Alvsåker (RIF, Norway)\n",
      "• Michel Bernard (Castaing Bernard (C Bernard (C Bernard (C Bernard (C Bernard (C Bernard (C Bernard (C Bernard (C Bernard (C Bernard (C Bernard (C Bernard (C Bernard (C Bernard (C Bernard (C Bernard (C Bernard (C Bernard (C\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                   chain_type='stuff',\n",
    "                                   retriever=vector_store.as_retriever(search_kwargs={'k': 2}),\n",
    "                                   return_source_documents=False,\n",
    "                                   chain_type_kwargs={'prompt': qa_prompt})\n",
    "\n",
    "\n",
    "\n",
    "user_input = \"who all are the members of EFCA BIM Task Force\"\n",
    "\n",
    "\n",
    "result=chain({'query':user_input})\n",
    "print(f\"Answer:{result['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:The EFCA BIM Task Force has developed a booklet that explains the use of ISO 19650 in the construction process.\n"
     ]
    }
   ],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                   chain_type='stuff',\n",
    "                                   retriever=vector_store.as_retriever(search_kwargs={'k': 2}),\n",
    "                                   return_source_documents=False,\n",
    "                                   chain_type_kwargs={'prompt': qa_prompt})\n",
    "\n",
    "\n",
    "\n",
    "user_input = \"what does EFCA booklet explains?\"\n",
    "\n",
    "\n",
    "result=chain({'query':user_input})\n",
    "print(f\"Answer:{result['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Directory not found: 'data/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m loader\u001b[38;5;241m=\u001b[39mDirectoryLoader(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m                        glob\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m                        loader_cls\u001b[38;5;241m=\u001b[39mPyPDFLoader)\n\u001b[1;32m----> 5\u001b[0m documents\u001b[38;5;241m=\u001b[39m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sayantika\\anaconda3\\envs\\cpullama\\lib\\site-packages\\langchain_community\\document_loaders\\directory.py:117\u001b[0m, in \u001b[0;36mDirectoryLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load documents.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sayantika\\anaconda3\\envs\\cpullama\\lib\\site-packages\\langchain_community\\document_loaders\\directory.py:123\u001b[0m, in \u001b[0;36mDirectoryLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m p \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory not found: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected directory, got file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Directory not found: 'data/'"
     ]
    }
   ],
   "source": [
    "loader=DirectoryLoader('data/',\n",
    "                       glob=\"*.pdf\",\n",
    "                       loader_cls=PyPDFLoader)\n",
    "\n",
    "documents=loader.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Sayantika\\\\OneDrive - IIT Delhi\\\\Desktop\\\\GenerativeAI\\\\research'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "#reason why 'data/' not detected\n",
    "#I am inside research dir . Need to exit from research dir\n",
    "#os.getcwd() should be done from app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

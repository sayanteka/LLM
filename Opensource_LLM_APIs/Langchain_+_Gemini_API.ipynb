{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QIUaVku4Wj0O"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import userdata\n",
        "google_api_key=userdata.get('google_api_key')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "genai.configure(api_key=google_api_key)"
      ],
      "metadata": {
        "id": "75A6aLxmXJiw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_CONFIG = {\n",
        "  \"temperature\": 0.2}"
      ],
      "metadata": {
        "id": "I3mP5-Xqihpa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = genai.GenerativeModel(model_name = \"gemini-1.0-pro\",\n",
        "                              generation_config = MODEL_CONFIG)"
      ],
      "metadata": {
        "id": "EaJv9QcSXQ6v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q_3whuhZZet",
        "outputId": "19046a65-432b-4d45-df72-d89747c25cdf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.30 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.30)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.37)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.38)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.37->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkKJMdSwbDEE",
        "outputId": "b93a82a0-1ff8-4fa6-a1c9-d7a60d153339"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: google-generativeai<0.5.0,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.1.37)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (2.11.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (2.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (4.10.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (1.23.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (0.1.38)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (23.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (8.2.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-google-genai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai) (3.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-google-genai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-google-genai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-google-genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-google-genai) (2024.2.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (1.63.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (1.62.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q --upgrade google-generativeai langchain-google-genai"
      ],
      "metadata": {
        "id": "d1N3zGNohqZ9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gemini API + Langchain**"
      ],
      "metadata": {
        "id": "IoqLbPdfj9vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('google_api_key')\n",
        "\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
      ],
      "metadata": {
        "id": "_KSSeNLvjNU_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
        "                             temperature=0.7)\n",
        "\n",
        "\n",
        "result = llm.invoke(\"What is a LLM?\")\n",
        "\n",
        "Markdown(result.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "ND6THy4UgAE1",
        "outputId": "8f97af84-f2a7-4836-8ad0-7b17f55114ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "LLM stands for **Large Language Model**.\n\nLLMs are a type of artificial intelligence (AI) that are trained on massive datasets of text and code. They are designed to understand and generate human-like text, and to perform a variety of language-related tasks, such as:\n\n* **Natural language understanding (NLU)**: Understanding the meaning of text.\n* **Natural language generation (NLG)**: Generating text from data or instructions.\n* **Machine translation**: Translating text from one language to another.\n* **Text summarization**: Summarizing long pieces of text into shorter ones.\n* **Question answering**: Answering questions based on a given context.\n* **Code generation**: Generating code from natural language instructions.\n\nLLMs are typically trained on billions or even trillions of words of text, and they use a variety of deep learning techniques to learn the patterns and relationships in language. This allows them to generate text that is both coherent and fluent, and to perform language-related tasks with a high degree of accuracy.\n\nSome of the most well-known LLMs include:\n\n* **GPT-3** from OpenAI\n* **BLOOM** from Google AI\n* **Jurassic-1** from AI21 Labs\n* **Megatron-Turing NLG** from Microsoft and NVIDIA\n\nLLMs are still under development, but they have already shown great promise for a wide range of applications, including:\n\n* **Chatbots and virtual assistants**: Providing natural language-based customer support and information.\n* **Content creation**: Generating marketing copy, news articles, and other written content.\n* **Language learning**: Helping people to learn new languages.\n* **Education**: Providing personalized learning experiences and answering student questions.\n* **Healthcare**: Assisting doctors with diagnosis and treatment planning.\n\nAs LLMs continue to improve, they are likely to have an even greater impact on our lives. They have the potential to revolutionize the way we communicate, learn, and work."
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest one fency name for this.\"\n",
        ")"
      ],
      "metadata": {
        "id": "7L7C0si_jkBA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
        "response=chain.run(\"Mexican\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok5Yv2najsQY",
        "outputId": "dd8555a3-4d7b-475e-86f6-ad47b2fab311"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Hacienda de los Sabores\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sequential Chain**"
      ],
      "metadata": {
        "id": "GFAU4zTBkcIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest one fency name for this.\"\n",
        ")\n",
        "\n",
        "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")"
      ],
      "metadata": {
        "id": "j9CdSoNgkM18"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables = ['restaurant_name'],\n",
        "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
        ")\n",
        "\n",
        "food_items_chain =LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")"
      ],
      "metadata": {
        "id": "0aLFyoQ5k7jA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "chain = SequentialChain(\n",
        "    chains = [name_chain, food_items_chain],\n",
        "    input_variables = ['cuisine'],\n",
        "    output_variables = ['restaurant_name', \"menu_items\"]\n",
        ")"
      ],
      "metadata": {
        "id": "x5tl2WsNlD44"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain({\"cuisine\": \"indian\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6sB2LqGlIuC",
        "outputId": "94de13db-868d-4961-f689-d2e8a07d8a86"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cuisine': 'indian', 'restaurant_name': 'Tandoori Royale', 'menu_items': '**Appetizers**\\n\\n* **Tandoori Chicken Tikka:** Boneless chicken marinated in yogurt, spices, and herbs, grilled in a tandoor\\n* **Vegetable Samosas:** Crispy pastries filled with a savory vegetable mixture of potatoes, peas, and spices\\n* **Onion Bhajis:** Fried onion fritters seasoned with cumin and coriander\\n* **Papadum:** Thin, crispy lentil crackers served with chutney\\n* **Mango Lassi:** A refreshing yogurt-based drink blended with mango pulp\\n\\n**Main Courses**\\n\\n* **Tandoori Mixed Grill:** A platter of tandoori-grilled meats including chicken, lamb, and shrimp\\n* **Butter Chicken:** Creamy tomato-based curry with boneless chicken\\n* **Palak Paneer:** Spinach-based curry with cubes of paneer cheese\\n* **Lamb Vindaloo:** Spicy Goan curry with tender lamb\\n* **Vegetable Biryani:** Aromatic rice dish with vegetables, spices, and herbs\\n* **Rogan Josh:** Kashmiri lamb curry with aromatic spices\\n\\n**Sides**\\n\\n* **Naan:** Soft, fluffy flatbread\\n* **Paratha:** Layered whole-wheat flatbread\\n* **Roti:** Whole-wheat flatbread\\n* **Raita:** Yogurt-based sauce with cucumber and spices\\n* **Dal Makhani:** Creamy lentil dish\\n\\n**Desserts**\\n\\n* **Gulab Jamun:** Sweet dumplings made from milk solids, soaked in a sugary syrup\\n* **Rasmalai:** Cottage cheese dumplings soaked in a sweet, creamy sauce\\n* **Mango Kulfi:** Indian ice cream made with mango pulp\\n* **Pistachio Burfi:** Sweet fudge made with pistachios\\n* **Sweet Lassi:** Yogurt-based drink blended with sugar and spices'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ConversationBufferMemory**"
      ],
      "metadata": {
        "id": "5AobkOtFmWec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
        "name = chain.run(\"Mexican\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRNyHuY9lOhY",
        "outputId": "ee8833dd-b6dd-4e83-b9d3-2cd3288b1928"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El Palacio de los Sabores Exquisitos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = chain.run(\"Arabic\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYBRPDtSmp-p",
        "outputId": "564adfb1-bc8c-4c3d-b5eb-424adab67ddd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Al-Majlis al-Maliki\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fwjfLZKmvlK",
        "outputId": "2d2975aa-8c55-4108-cac8-4b48c485ad3b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Mexican\n",
            "AI: El Palacio de los Sabores Exquisitos\n",
            "Human: Arabic\n",
            "AI: Al-Majlis al-Maliki\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ConversationChain**"
      ],
      "metadata": {
        "id": "cHAaA3W6m-B-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "\n",
        "convo = ConversationChain(llm=llm)\n",
        "print(convo.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eREnCHyZm7_M",
        "outputId": "368cc464-0345-4456-ea9b-fe2b33989ff6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who won the first cricket world cup?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hNJzeN92nQ2L",
        "outputId": "ba696a8d-72f5-4f6d-a5ea-2abbf4db271f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'West Indies'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who was the captain ofthe winning team?\") #wrong answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9GruiSg7nbPG",
        "outputId": "67b40952-9b62-4381-8727-18d3f82ceda4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Frank Worrell'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QVvWLhnjnqnd",
        "outputId": "817175de-fe24-45a7-ecf4-1cc4615e2985"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who was the captain ofthe first cricket world cup?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SXSs-dYNn7Ez",
        "outputId": "5fc95f27-85ce-4334-d8aa-978c2cf14f51"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Frank Worrell'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(convo.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gknG4vUonwqK",
        "outputId": "b2155713-7ff0-4f56-e8f0-68830e2c409a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Who won the first cricket world cup?\n",
            "AI: West Indies\n",
            "Human: Who was the captain ofthe winning team?\n",
            "AI: Frank Worrell\n",
            "Human: How much is 5+5?\n",
            "AI: 10\n",
            "Human: Who was the captain ofthe first world cup?\n",
            "AI: Frank Worrell\n",
            "Human: Who was the captain ofthe first cricket world cup?\n",
            "AI: Frank Worrell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ConversationBufferWindowMemory**"
      ],
      "metadata": {
        "id": "qt9GVjOYoeD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=1)\n",
        "\n",
        "convo = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory\n",
        ")\n",
        "convo.run(\"Who was the captain of first cricket world cup?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3Ko_dhc-oGdN",
        "outputId": "0a49e810-a382-4590-bdeb-4ae1233c04d2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'**AI:** Clive Lloyd'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Without Langchain**"
      ],
      "metadata": {
        "id": "CebMG93ZkIg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "local_llm=model"
      ],
      "metadata": {
        "id": "o2hMLzYsjQGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8_78f_9bgT3",
        "outputId": "5facb5b3-d4c7-4c43-9d7c-11b445db271f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " genai.GenerativeModel(\n",
              "   model_name='models/gemini-1.0-pro',\n",
              "   generation_config={'temperature': 0.2}.\n",
              "   safety_settings={}\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = local_llm.generate_content(\"I want to open a restaurant for Chinese food. Suggest one fency name for this.\")\n"
      ],
      "metadata": {
        "id": "QVQbnJgwbj15"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(name.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDWCQUdscAH3",
        "outputId": "d4034954-a718-4d93-d732-6314abdf035b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Celestial Dynasty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done.\n",
        "\n",
        "When used correctly agents can be extremely powerful. In order to load agents, you should understand the following concepts:\n",
        "\n",
        "Tool: A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains.\n",
        "LLM: The language model powering the agent.\n",
        "Agent: The agent to use."
      ],
      "metadata": {
        "id": "vstDr9y-ruUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/RGGH/OpenAI_SQL/blob/master/LangChain_01.ipynb"
      ],
      "metadata": {
        "id": "Kla7ycRvrtqg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}